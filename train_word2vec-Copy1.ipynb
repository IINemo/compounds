{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import msgpack\n",
    "import time\n",
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model without compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorSentences:\n",
    "    def __init__(self, dir_path):\n",
    "        self._dir_path = dir_path\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self._dir_path):\n",
    "            file_path = os.path.join(self._dir_path, fname)\n",
    "            \n",
    "            with open(file_path, 'rb') as f:\n",
    "                annots = msgpack.unpackb(f.read(), raw=False)\n",
    "            \n",
    "            if annots:\n",
    "                for doc_annots in annots:\n",
    "                    for sent in doc_annots:\n",
    "                        yield sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "#parse_path = '/notebook/projects/compounds/workdir/parse1/'\n",
    "parse_path = '/notebook/projects/compounds/workdir/parse5/'\n",
    "model = gensim.models.Word2Vec(GeneratorSentences(parse_path), min_count=5, size=100, workers=10)\n",
    "model.save('./model_word2vec_no_compounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('чистить', 0.9070878624916077),\n",
       " ('помыть', 0.8470351696014404),\n",
       " ('мочить', 0.8346104621887207),\n",
       " ('протирать', 0.8309078216552734),\n",
       " ('намазывать', 0.8274841904640198),\n",
       " ('мыться', 0.8230193257331848),\n",
       " ('полоскать', 0.8215987682342529),\n",
       " ('вытирать', 0.8136080503463745),\n",
       " ('мазать', 0.8098058700561523),\n",
       " ('замачивать', 0.8080874681472778)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('мыть')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Часть 1</th>\n",
       "      <th>Часть 2</th>\n",
       "      <th>Ответ Елены</th>\n",
       "      <th>Ответ Дмитрия</th>\n",
       "      <th>Катя (модератор)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>автор</td>\n",
       "      <td>программы</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>атмосфера</td>\n",
       "      <td>городов</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>новый</td>\n",
       "      <td>год</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>тонна</td>\n",
       "      <td>грязи</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>второй</td>\n",
       "      <td>эшелон</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Часть 1    Часть 2  Ответ Елены  Ответ Дмитрия  Катя (модератор)\n",
       "0      автор  программы            2              2                 2\n",
       "1  атмосфера    городов            2              2                 2\n",
       "2      новый        год            2              2                 2\n",
       "3      тонна      грязи            2              2                 2\n",
       "4     второй     эшелон            1              2                 2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds_path = './workdir/annotation_katya_ref.csv'\n",
    "df_compounds = pd.read_csv(compounds_path)\n",
    "df_compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.processor_sentence_splitter import ProcessorSentenceSplitter\n",
    "from isanlp.ru.processor_tokenizer_ru import ProcessorTokenizerRu\n",
    "from isanlp.ru.processor_mystem import ProcessorMystem\n",
    "from isanlp import PipelineCommon\n",
    "from isanlp.wrapper_multi_process_document import WrapperMultiProcessDocument\n",
    "\n",
    "\n",
    "ppl = PipelineCommon([\n",
    "    (ProcessorTokenizerRu(), ['text'], {0 : 'tokens'}),\n",
    "    (ProcessorSentenceSplitter(), ['tokens'], {0 : 'sentences'}),\n",
    "    (ProcessorMystem(), ['tokens', 'sentences'], {'lemma' : 'lemma'})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['год_обучение',\n",
       " 'электролитный_обмен',\n",
       " 'сведение_полиция',\n",
       " 'световой_импульс',\n",
       " 'духовный_культура']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_set = set()\n",
    "for i in df_compounds.index:\n",
    "    compound = '{} {}'.format(df_compounds.loc[i, 'Часть 1'], df_compounds.loc[i, 'Часть 2'])\n",
    "    lemmas = ppl(compound)['lemma'][0]\n",
    "    compound_set.add('{}_{}'.format(lemmas[0], lemmas[1]))\n",
    "                     \n",
    "print(len(compound_set))\n",
    "list(compound_set)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorSentencesCompounds:\n",
    "    def __init__(self, dir_path):\n",
    "        self._dir_path = dir_path\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self._dir_path):\n",
    "            file_path = os.path.join(self._dir_path, fname)\n",
    "            \n",
    "            with open(file_path, 'rb') as f:\n",
    "                annots = msgpack.unpackb(f.read(), raw=False)\n",
    "            \n",
    "            if annots:\n",
    "                for doc_annots in annots:\n",
    "                    for sent in doc_annots:\n",
    "                        additional_sent = []\n",
    "                        for i in range(len(sent) - 1):\n",
    "                            compound = '{}_{}'.format(sent[i], sent[i + 1])\n",
    "                            if compound in compound_set:\n",
    "                                additional_sent.append(sent[:i] + [compound] + sent[i + 2:])\n",
    "                            \n",
    "                        yield sent\n",
    "                        for add_sent in additional_sent:\n",
    "                            yield add_sent\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "parse_path = '/notebook/projects/compounds/workdir/parse5/'\n",
    "save_path = './workdir/models/model_word2vec_compounds5'\n",
    "model = gensim.models.Word2Vec(GeneratorSentencesCompounds(parse_path), min_count=5, size=500, workers=5)\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.7/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('соведущий', 0.6568776369094849),\n",
       " ('модератор', 0.6474907398223877),\n",
       " ('колумнист', 0.6105226278305054),\n",
       " ('фрилансер', 0.6065789461135864),\n",
       " ('соорганизатор', 0.6028417348861694),\n",
       " ('руководитель_компания', 0.6026309728622437),\n",
       " ('редактор', 0.6008354425430298),\n",
       " ('сегоднячко', 0.6001319289207458),\n",
       " ('сооснователь', 0.5991875529289246),\n",
       " ('медиапроект', 0.599036693572998)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('автор_программа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_path = '/notebook/projects/compounds/workdir/parse5'\n",
    "full_data = list(GeneratorSentencesCompounds(parse_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(full_data, min_count=2, size=300, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './workdir/models/model_word2vec_compounds6'\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.7/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('программа', 0.5615918636322021),\n",
       " ('телепрограмма', 0.5530967712402344),\n",
       " ('соведущий', 0.5281647443771362),\n",
       " ('телепередача', 0.5098356604576111),\n",
       " ('колумнист', 0.5057438611984253),\n",
       " ('телеигра', 0.4916815757751465),\n",
       " ('модератор', 0.478797972202301),\n",
       " ('телекритика', 0.47347599267959595),\n",
       " ('рубрика', 0.4733657240867615),\n",
       " ('медиапроект', 0.47168201208114624)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('автор_программа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './workdir/models/model_fasttext_compounts_1'\n",
    "model_fasttext = gensim.models.FastText(full_data, size=300, window=5, min_count=2, workers=6)\n",
    "model_fasttext.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
