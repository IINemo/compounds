{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:00<00:00, 30.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 examples retrieved for experiment\n",
      "Classification data created with shape (199, 900)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 31.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.8672\n",
      "precision= ['0.9562', '0.3995']\n",
      "recall= ['0.8941', '0.6568']\n",
      "f1= ['0.9231', '0.4703']\n",
      "spearman= 0.4321\n",
      "roc_auc= 0.7755\n",
      ".....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "from pymystem3 import Mystem\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "morph = Mystem()\n",
    "\n",
    "\n",
    "compounds_path = './workdir/annotation_small_selected.csv'\n",
    "\n",
    "def acquiring(wordvecs, compvecs):\n",
    "    comp = pd.read_csv(compounds_path)\n",
    "\n",
    "#     part1 = list(comp['Часть 1'].values)[250:]\n",
    "#     part2 = list(comp['Часть 2'].values)[250:]\n",
    "#     values = list(comp['Катя (short list)'].values)[250:]\n",
    "    #part1 = list\n",
    "    \n",
    "    part1 = list(comp['Часть 1'].values)\n",
    "    part2 = list(comp['Часть 2'].values)\n",
    "    values = list(comp['Катя (short list)'].values)\n",
    "    \n",
    "    print('Number of examples: ', len(values))\n",
    "\n",
    "    compounds = []\n",
    "    classes = []\n",
    "\n",
    "    for w1, w2, v in zip(part1, part2, values):\n",
    "        if v != 2 and v != -1:\n",
    "            lem_w1 = morph.lemmatize(w1)[0]\n",
    "            lem_w2 = morph.lemmatize(w2)[0]\n",
    "            compounds.append('_'.join([lem_w1, lem_w2]))\n",
    "            classes.append(v)\n",
    "\n",
    "    vecs1 = []\n",
    "    vecs2 = []\n",
    "    vecsc = []\n",
    "    true_comp_class = []\n",
    "\n",
    "    words = []\n",
    "    comps = []\n",
    "    \n",
    "    with open(wordvecs) as w:\n",
    "        for line in w:\n",
    "            words.append(line.split())\n",
    "\n",
    "    with open(compvecs) as c:\n",
    "        for line in c:\n",
    "            comps.append(line.split())\n",
    "\n",
    "    for compound, value in zip(compounds, classes):\n",
    "        comp_flag = 0\n",
    "        w1_flag = 0\n",
    "        w2_flag = 0\n",
    "        for line in comps:\n",
    "            if compound == line[0]:\n",
    "                vecc = np.array(line[1:]).astype(np.float32)\n",
    "                comp_flag = 1\n",
    "        w1 = compound.split('_')[0]\n",
    "        w2 = compound.split('_')[1]\n",
    "        if comp_flag:\n",
    "            for line in words:\n",
    "                if w1 == line[0]:\n",
    "                    vec1 = np.array(line[1:]).astype(np.float32)\n",
    "                    w1_flag = 1\n",
    "                    break\n",
    "            for line in words:\n",
    "                if w2 == line[0]:\n",
    "                    w2_flag = 1\n",
    "                    vec2 = np.array(line[1:]).astype(np.float32)\n",
    "                    break\n",
    "        if comp_flag and w1_flag and w2_flag:\n",
    "            vecs1.append(vec1)\n",
    "            vecs2.append(vec2)\n",
    "            vecsc.append(vecc)\n",
    "            true_comp_class.append(value)\n",
    "\n",
    "    print(len(vecsc), 'examples retrieved for experiment')\n",
    "    return vecs1, vecs2, vecsc, true_comp_class\n",
    "\n",
    "def make_train_data(w1vecs, w2vecs, compvecs):\n",
    "    train = np.concatenate((np.array(w1vecs), np.array(w2vecs), np.array(compvecs)), axis=1)\n",
    "    print('Classification data created with shape', train.shape)\n",
    "    return train\n",
    "\n",
    "\n",
    "wordvecs_path = './workdir/vectors_parts.txt'\n",
    "compvecs_path = './workdir/vectors_compounds.txt'\n",
    "# parser = ArgumentParser(description='Unsupervised metrics experiment')\n",
    "# parser.add_argument('wordvecs', help='word vectors dump')\n",
    "# parser.add_argument('compvecs', help='compounds vectors dump')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "w1, w2, c, true = acquiring(wordvecs_path, compvecs_path)\n",
    "\n",
    "vecs = make_train_data(w1, w2, c)\n",
    "\n",
    "accuracies = []\n",
    "precision1 = []\n",
    "precision0 = []\n",
    "recall1 = []\n",
    "recall0 = []\n",
    "f11 = []\n",
    "f10 = []\n",
    "spearman = []\n",
    "rocaucs = []\n",
    "\n",
    "Cs = [1]\n",
    "kernels = [1]\n",
    "for C in Cs:\n",
    "    for kernel in kernels:\n",
    "        print(C, kernel)\n",
    "        for state in tqdm(range(71, 71+25)):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(vecs, true, test_size=.25, random_state=state)\n",
    "\n",
    "            clf = SVC(C=10, kernel='linear', random_state=51, class_weight='balanced')\n",
    "            #clf = MLPClassifier(alpha=1, solver='lbfgs', hidden_layer_sizes=(200,20,20, ), random_state=42)\n",
    "            #clf = DecisionTreeClassifier(max_depth=10, max_features=20, random_state=42)\n",
    "            #clf = GaussianNB()\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_test)\n",
    "            accuracies.append(accuracy_score(pred, y_test))\n",
    "            precision1.append(precision_score(pred, y_test))\n",
    "            precision0.append(precision_score(pred, y_test, pos_label=0))\n",
    "            recall1.append(recall_score(pred, y_test))\n",
    "            recall0.append(recall_score(pred, y_test, pos_label=0))\n",
    "            f11.append(f1_score(pred, y_test))\n",
    "            f10.append(f1_score(pred, y_test, pos_label=0))\n",
    "            #print(pred, y_test)\n",
    "            try:\n",
    "                rocaucs.append(roc_auc_score(pred, y_test))\n",
    "            except:\n",
    "                pass\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('error')\n",
    "                try:\n",
    "                    corr = spearmanr(pred, y_test)[0]\n",
    "                    spearman.append(corr)\n",
    "                except Warning:\n",
    "                    spearman.append(0)\n",
    "\n",
    "\n",
    "        print('accuracy=', '%.4f' % np.mean(accuracies))\n",
    "        print('precision=', ['%.4f' % np.mean(precision1), '%.4f' % np.mean(precision0)])\n",
    "        print('recall=', ['%.4f' % np.mean(recall1), '%.4f' % np.mean(recall0)])\n",
    "        print('f1=',['%.4f' % np.mean(f11), '%.4f' % np.mean(f10)])\n",
    "        print('spearman=', '%.4f' % np.mean(spearman))\n",
    "        print('roc_auc=', '%.4f' % np.mean(rocaucs))\n",
    "\n",
    "        print('.....................................')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
