{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./workdir/annotation_small.csv')\n",
    "dataset[dataset['Катя (short list)'].isin({1.0, 0.0})].to_csv('./workdir/annotation_small_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model_path = './workdir/models/model_word2vec_test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "loaded\n",
      "2720494\n",
      "Starting lemmatize\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "morph = Mystem()\n",
    "\n",
    "model_path = global_model_path\n",
    "vectors_path = './workdir/vectors_parts.txt'\n",
    "#compounds_path = './workdir/annotation_katya_selected.csv'\n",
    "compounds_path = './workdir/annotation_small_selected.csv'\n",
    "\n",
    "comp = pd.read_csv(compounds_path)\n",
    "\n",
    "chast1 = list(comp['Часть 1'].values)\n",
    "chast2 = list(comp['Часть 2'].values)\n",
    "\n",
    "print('loading model')\n",
    "model = FastText.load(model_path)\n",
    "print('loaded')\n",
    "print(len(model.wv.vocab))\n",
    "\n",
    "part1_lem = []\n",
    "part2_lem = []\n",
    "\n",
    "print('Starting lemmatize')\n",
    "\n",
    "for w1, w2 in zip(chast1, chast2):\n",
    "    lem_w1 = morph.lemmatize(w1)[0]\n",
    "    lem_w2 = morph.lemmatize(w2)[0]\n",
    "    part1_lem.append(lem_w1)\n",
    "    part2_lem.append(lem_w2)\n",
    "\n",
    "with open(vectors_path, 'w') as vectors:\n",
    "    for w1, w2 in zip(part1_lem, part2_lem):\n",
    "        if w1 in model.wv.vocab:\n",
    "            vectors.write(w1 + ' ' + ' '.join(model.wv[w1].astype('str')) + '\\r\\n')\n",
    "        else:\n",
    "            print(w1)\n",
    "        if w2 in model.wv.vocab:\n",
    "            vectors.write(w2 + ' ' + ' '.join(model.wv[w2].astype('str')) + '\\r\\n')\n",
    "        else:\n",
    "            print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "loaded\n",
      "2720494\n",
      "Starting lemmatize\n",
      "приговор_судно\n",
      "красный_черт\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from gensim.models import FastText\n",
    "\n",
    "morph = Mystem()\n",
    "\n",
    "#model_path = './workdir/models/model_fast2vec_300_5'\n",
    "model_path = global_model_path\n",
    "vector_path = './workdir/vectors_compounds.txt'\n",
    "#compounds_path = './workdir/annotation_katya_selected.csv'\n",
    "compounds_path = './workdir/annotation_small_selected.csv'\n",
    "\n",
    "\n",
    "comp = pd.read_csv(compounds_path)\n",
    "\n",
    "chast1 = list(comp['Часть 1'].values)\n",
    "chast2 = list(comp['Часть 2'].values)\n",
    "\n",
    "print('loading model')\n",
    "model = FastText.load(model_path)\n",
    "print('loaded')\n",
    "print(len(model.wv.vocab))\n",
    "\n",
    "comp_lem = []\n",
    "\n",
    "print('Starting lemmatize')\n",
    "\n",
    "for w1, w2 in zip(chast1, chast2):\n",
    "    lem_w1 = morph.lemmatize(w1)[0]\n",
    "    lem_w2 = morph.lemmatize(w2)[0]\n",
    "    comp_lem.append(lem_w1 + '_' + lem_w2)\n",
    "\n",
    "with open(vector_path, 'w') as vectors:\n",
    "    for w1 in comp_lem:\n",
    "        if w1 in model.wv.vocab:\n",
    "            vectors.write(w1 + ' ' + ' '.join(model.wv[w1].astype('str')) + '\\r\\n')\n",
    "        else:\n",
    "            print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "201\n",
      "201\n",
      "приговор судно приговор_судно 0 0 0\n",
      "красный черт красный_черт 0 0 0\n",
      "199 examples retrieved for experiment\n",
      "0.3593346066740859\n",
      "-0.07977275893692432\n",
      "-0.13168458415557954\n",
      "-0.13239896707143256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial import distance\n",
    "from pymystem3 import Mystem\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "#compounds_path = './workdir/annotation_katya_selected.csv'\n",
    "compounds_path = './workdir/annotation_small_selected.csv'\n",
    "\n",
    "morph = Mystem()\n",
    "\n",
    "def acquiring(wordvecs, compvecs):\n",
    "    comp = pd.read_csv(compounds_path)\n",
    "\n",
    "    part1 = list(comp['Часть 1'].values)\n",
    "    part2 = list(comp['Часть 2'].values)\n",
    "    values = list(comp['Катя (short list)'].values)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    compounds = []\n",
    "    classes = []\n",
    "\n",
    "    for w1, w2, v in zip(part1, part2, values):\n",
    "        if v != 2:\n",
    "            lem_w1 = morph.lemmatize(w1)[0]\n",
    "            lem_w2 = morph.lemmatize(w2)[0]\n",
    "            compounds.append('_'.join([lem_w1, lem_w2]))\n",
    "            classes.append(v)\n",
    "\n",
    "    vecs1 = []\n",
    "    vecs2 = []\n",
    "    vecsc = []\n",
    "    true_comp_class = []\n",
    "\n",
    "    words = []\n",
    "    comps = []\n",
    "    \n",
    "    with open(wordvecs) as w:\n",
    "        for line in w:\n",
    "            words.append(line.split())\n",
    "\n",
    "    with open(compvecs) as c:\n",
    "        for line in c:\n",
    "            comps.append(line.split())\n",
    "\n",
    "    print(len(compounds))\n",
    "    print(len(values))\n",
    "    for compound, value in zip(compounds, values):\n",
    "        comp_flag = 0\n",
    "        w1_flag = 0\n",
    "        w2_flag = 0\n",
    "        for line in comps:\n",
    "            if compound == line[0]:\n",
    "                vecc = np.array(line[1:]).astype(np.float32)\n",
    "                comp_flag = 1\n",
    "        w1 = compound.split('_')[0]\n",
    "        w2 = compound.split('_')[1]\n",
    "        if comp_flag:\n",
    "            for line in words:\n",
    "                if w1 == line[0]:\n",
    "                    vec1 = np.array(line[1:]).astype(np.float32)\n",
    "                    w1_flag = 1\n",
    "                    break\n",
    "            for line in words:\n",
    "                if w2 == line[0]:\n",
    "                    w2_flag = 1\n",
    "                    vec2 = np.array(line[1:]).astype(np.float32)\n",
    "                    break\n",
    "        if comp_flag and w1_flag and w2_flag:\n",
    "            vecs1.append(vec1)\n",
    "            vecs2.append(vec2)\n",
    "            vecsc.append(vecc)\n",
    "            true_comp_class.append(value)\n",
    "        else:\n",
    "            print(w1, w2, compound, comp_flag, w1_flag, w2_flag)\n",
    "\n",
    "    print(len(vecsc), 'examples retrieved for experiment')\n",
    "    return vecs1, vecs2, vecsc, true_comp_class\n",
    "\n",
    "\n",
    "def get_mean(part1_vecs, part2_vecs):\n",
    "    parts_mean = []\n",
    "    for vec1, vec2 in zip(part1_vecs, part2_vecs):\n",
    "        parts_mean.append((vec1 + vec2) / 2)\n",
    "\n",
    "    return parts_mean\n",
    "\n",
    "\n",
    "def cosine_between_parts_and_compound(part1_vecs, part2_vecs, comp_vecs, true_class):\n",
    "    parts_mean = get_mean(part1_vecs, part2_vecs)\n",
    "\n",
    "    cosines = []\n",
    "    for w, c in zip(parts_mean, comp_vecs):\n",
    "        cosines.append(abs(1 - distance.cosine(w, c)))\n",
    "    \n",
    "    print(spearmanr(cosines, true_class)[0])\n",
    "\n",
    "\n",
    "def chebyshev_between_parts_and_compound(part1_vecs, part2_vecs, comp_vecs, true_class):\n",
    "    parts_mean = get_mean(part1_vecs, part2_vecs)\n",
    "\n",
    "    chebyshevs = []\n",
    "    for w, c in zip(parts_mean, comp_vecs):\n",
    "        chebyshevs.append(abs(distance.chebyshev(w, c)))\n",
    "\n",
    "    print(spearmanr(chebyshevs, true_class)[0])\n",
    "\n",
    "\n",
    "def manhattan_between_parts_and_compound(part1_vecs, part2_vecs, comp_vecs, true_class):\n",
    "    parts_mean= get_mean(part1_vecs, part2_vecs)\n",
    "\n",
    "    manhattans = []\n",
    "    for w, c in zip(parts_mean, comp_vecs):\n",
    "        manhattans.append(abs(distance.cityblock(w, c)))\n",
    "    print(spearmanr(manhattans, true_class)[0])\n",
    "\n",
    "\n",
    "def euclidean_between_parts_and_compound(part1_vecs, part2_vecs, comp_vecs, true_class):\n",
    "    parts_mean= get_mean(part1_vecs, part2_vecs)\n",
    "\n",
    "    euclideans = []\n",
    "    for w, c in zip(parts_mean, comp_vecs):\n",
    "        euclideans.append(abs(distance.euclidean(w, c)))\n",
    "    print(spearmanr(euclideans, true_class)[0])\n",
    "\n",
    "\n",
    "vectors_parts_path = './workdir/vectors_parts.txt'\n",
    "vectors_compounds_path = './workdir/vectors_compounds.txt'\n",
    "\n",
    "w1, w2, c, true = acquiring(vectors_parts_path, vectors_compounds_path)\n",
    "\n",
    "cosine_between_parts_and_compound(w1, w2, c, true)\n",
    "chebyshev_between_parts_and_compound(w1, w2, c, true)\n",
    "manhattan_between_parts_and_compound(w1, w2, c, true)\n",
    "euclidean_between_parts_and_compound(w1, w2, c, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.7/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.19120477, -1.4227085 ,  0.07280233, -2.2622147 , -0.05061609,\n",
       "        0.05105349, -2.208469  , -0.06491596, -0.0322176 ,  1.1179839 ,\n",
       "        1.22782   ,  2.630733  , -3.0086253 , -0.9810795 , -1.6233798 ,\n",
       "        1.2038122 ,  0.92346174, -1.2351778 , -0.894103  , -0.976527  ,\n",
       "        0.01442312,  0.13855833, -0.23599832, -0.07819845, -0.36940575,\n",
       "        0.95845777, -1.2605244 , -0.87924594, -1.4497571 , -2.4237576 ,\n",
       "        2.5970576 , -0.0301838 , -0.5671605 ,  0.8208104 , -0.03633777,\n",
       "        2.1496432 ,  0.5412136 , -1.2187197 , -0.13529265,  0.72096914,\n",
       "        1.0065191 , -0.23205145,  0.16050196, -1.2166207 , -2.0707355 ,\n",
       "       -1.2792473 , -1.1825869 ,  0.7249201 , -1.6045942 ,  0.18434829,\n",
       "        0.42369962,  0.8223133 , -0.9105033 ,  0.13977809,  2.4988577 ,\n",
       "       -0.28781703,  1.1641194 ,  0.37301946, -1.0414828 , -0.56199586,\n",
       "       -2.5995567 , -0.7153463 ,  0.20854273, -0.6626351 ,  1.3331832 ,\n",
       "        0.18200372, -0.58380735, -1.0062047 ,  0.22278368,  1.3395969 ,\n",
       "       -1.3435891 , -1.4168711 , -0.917313  ,  1.2116213 , -0.01176282,\n",
       "       -0.31779972, -1.2211771 , -1.5099112 , -0.5725791 ,  0.7422644 ,\n",
       "       -1.1183358 , -1.1677408 ,  2.9229407 ,  0.82118416, -0.5255069 ,\n",
       "        0.57058644, -1.384654  ,  1.104     ,  1.2659078 , -1.2669361 ,\n",
       "        1.6912644 ,  0.8078344 ,  0.3869235 ,  0.83827275,  0.71299505,\n",
       "        0.5846093 ,  1.4992101 ,  0.05154509,  1.3918759 , -2.6664395 ,\n",
       "       -0.8687509 , -0.3037307 , -0.3664393 ,  0.10493413, -1.429195  ,\n",
       "       -2.1892114 , -0.7535136 , -0.41787374,  0.8231731 , -0.9684065 ,\n",
       "        0.57025796,  0.2819842 , -1.5955478 , -2.526508  ,  0.6688184 ,\n",
       "        0.01683449, -0.5773442 , -1.671479  , -1.3713993 ,  0.85876644,\n",
       "       -0.15499316, -0.01394929,  0.5574081 ,  0.04499502, -0.55111   ,\n",
       "        0.30457965, -0.55274355,  0.16774753,  0.8043383 ,  0.9000899 ,\n",
       "       -3.3552873 ,  1.0420654 , -0.7170922 , -1.727926  ,  0.4056242 ,\n",
       "        0.6655588 , -0.84145206, -2.347755  ,  1.4218361 ,  0.7054412 ,\n",
       "        0.6450265 ,  1.4889646 , -1.0284661 ,  2.6016152 , -0.43511698,\n",
       "        0.6491201 , -0.31778353, -0.732792  , -1.8158205 ,  1.5603856 ,\n",
       "       -0.6634204 ,  0.26650062,  0.7263436 , -1.0495337 ,  1.4307681 ,\n",
       "       -0.27335194,  0.16352862, -1.0811049 , -2.5911095 ,  0.5488974 ,\n",
       "       -1.4096518 , -0.66479826,  1.5049137 , -0.34553742, -0.96218556,\n",
       "        0.3664368 , -1.1090779 ,  0.06913603,  0.04222689,  1.6046244 ,\n",
       "       -0.4006834 , -0.3889271 ,  1.7242311 ,  0.9480454 , -0.28005856,\n",
       "        0.17389268, -2.346269  ,  1.9137795 ,  1.6686774 , -0.07823498,\n",
       "        0.29123318,  0.48692688,  2.0228884 , -0.41604015,  0.32466587,\n",
       "        2.282055  ,  0.4131536 , -0.42154193, -1.4179164 , -0.14471792,\n",
       "        0.8807052 ,  0.8980196 , -0.19755428, -0.10555461, -0.46394923,\n",
       "       -1.6206983 , -1.8069363 ,  0.1687207 ,  2.1906667 , -0.3185407 ,\n",
       "       -1.3033203 ,  0.514012  ,  0.7599563 , -1.7850248 , -2.074411  ,\n",
       "        1.1389346 ,  0.7862912 , -0.1694787 , -0.14097206,  1.423207  ,\n",
       "        0.46077174,  1.6059121 ,  2.3922548 ,  0.5810358 , -2.8559754 ,\n",
       "       -1.0915018 ,  0.60904276,  1.1794261 , -0.22106548,  1.4792157 ,\n",
       "       -0.8064798 ,  0.7441046 ,  0.98111445,  0.7035106 ,  1.1110183 ,\n",
       "       -1.7266722 ,  1.3022283 ,  3.0829098 , -2.0704746 ,  0.19830361,\n",
       "       -0.04131009, -0.47613892, -0.72023416,  1.0478072 , -0.73098457,\n",
       "       -1.1002693 ,  1.026373  ,  1.1206373 ,  0.6543754 , -0.37754092,\n",
       "        0.41881078, -1.4576641 ,  1.0613533 , -1.1340582 ,  0.8188238 ,\n",
       "       -0.75637794, -1.7066677 , -0.04811142, -2.4517565 , -0.67667675,\n",
       "        2.249444  , -1.490996  ,  2.8958414 ,  1.7010664 , -0.38129964,\n",
       "        1.5085994 ,  1.3028368 , -0.697702  ,  1.3426417 , -0.26879972,\n",
       "       -1.9666452 ,  0.9764951 , -2.2286918 , -0.48719332,  0.37495208,\n",
       "        0.36620227,  0.7894127 , -0.19073851, -0.38043252,  2.5300465 ,\n",
       "       -1.2105057 , -1.7645267 ,  0.87403065, -1.5325227 ,  0.06436455,\n",
       "       -1.1341846 ,  1.4829549 ,  2.6621609 ,  1.5060961 , -0.8038888 ,\n",
       "       -0.6497388 ,  0.2834284 , -1.0321567 ,  1.2939361 , -0.3597804 ,\n",
       "       -0.5001489 ,  2.3527267 ,  0.372806  ,  1.8226504 , -0.5084028 ,\n",
       "       -0.97791225,  0.89819616,  0.7585635 ,  0.47542706, -0.47655857,\n",
       "       -1.5327592 , -1.7734249 , -1.3267379 ,  0.02886762,  0.57372475],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['черт']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
